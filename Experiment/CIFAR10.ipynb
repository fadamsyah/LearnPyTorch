{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out, stride=1):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels_in, channels_out, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(channels_out)\n",
    "        self.conv2 = nn.Conv2d(channels_out, channels_out, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(channels_out)\n",
    "        \n",
    "        self.shortcut = None\n",
    "        if channels_in != channels_out:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(channels_in, channels_out, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(channels_out),\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        shct = x\n",
    "        if self.shortcut is not None: shct = self.shortcut(shct)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x += shct\n",
    "        x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetShallow(nn.Module):\n",
    "    def __init__(self, first_channels, num_blocks, num_classes):\n",
    "        super(ResNetShallow, self).__init__()\n",
    "        self.channels = first_channels\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, self.channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.channels)\n",
    "        self.layer1 = self._make_layer(num_blocks[0], False)\n",
    "        self.layer2 = self._make_layer(num_blocks[1], True)\n",
    "        self.layer3 = self._make_layer(num_blocks[2], True)\n",
    "        self.layer4 = self._make_layer(num_blocks[3], True)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc = nn.Linear(self.channels, num_classes)\n",
    "        \n",
    "    def _make_layer(self, num_blocks, downsample=True):\n",
    "        layers = []\n",
    "        for i in range(num_blocks):\n",
    "            if i==0 and downsample:\n",
    "                layers.append(ResBlock(self.channels, self.channels*2, 2))\n",
    "                self.channels *= 2\n",
    "            else:\n",
    "                layers.append(ResBlock(self.channels, self.channels, 1))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18(first_channels):\n",
    "    return ResNetShallow(first_channels, [2, 2, 2, 2], 10)\n",
    "\n",
    "def ResNet34(first_channels):\n",
    "    return ResNetShallow(first_channels, [3, 4, 6, 3], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=2),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.5),\n",
    "    transforms.RandomAffine(degrees=10., scale=(0.9,1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914009 , 0.48215896, 0.4465308), (0.24703279, 0.24348423, 0.26158753))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914009 , 0.48215896, 0.4465308), (0.24703279, 0.24348423, 0.26158753))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='../data', train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='../data', train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = trainset.__len__()\n",
    "num_test = testset.__len__()\n",
    "bs_train = 1024\n",
    "bs_test = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=bs_train, shuffle=True, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=bs_test, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'car', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet18(64)\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=50\n",
    "# num_triangle = 1\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.08, momentum=0.9, weight_decay=5e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.001, max_lr=1.0,\n",
    "#                                               step_size_up=int(epochs*len(trainloader)/2/num_triangle), mode='triangular2')\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, 0.8, epochs=epochs, steps_per_epoch=len(trainloader),\n",
    "                                                anneal_strategy='cos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training for 50 epoch\n",
      "Epoch: 1 || train_loss: 1.85062 || train_acc : 0.31466 || test_loss: 1.98400 || test_acc : 0.36220 \n",
      "Epoch: 2 || train_loss: 1.46473 || train_acc : 0.46522 || test_loss: 1.52801 || test_acc : 0.48030 \n",
      "Epoch: 3 || train_loss: 1.25937 || train_acc : 0.54566 || test_loss: 1.40796 || test_acc : 0.54170 \n",
      "Epoch: 4 || train_loss: 1.04914 || train_acc : 0.62850 || test_loss: 1.23037 || test_acc : 0.61740 \n",
      "Epoch: 5 || train_loss: 0.90766 || train_acc : 0.68386 || test_loss: 1.04192 || test_acc : 0.64890 \n",
      "Epoch: 6 || train_loss: 0.80087 || train_acc : 0.72196 || test_loss: 0.81511 || test_acc : 0.71370 \n",
      "Epoch: 7 || train_loss: 0.72884 || train_acc : 0.74816 || test_loss: 0.66504 || test_acc : 0.76440 \n",
      "Epoch: 8 || train_loss: 0.65671 || train_acc : 0.77190 || test_loss: 0.62871 || test_acc : 0.77390 \n",
      "Epoch: 9 || train_loss: 0.62561 || train_acc : 0.78568 || test_loss: 0.63788 || test_acc : 0.77410 \n",
      "Epoch: 10 || train_loss: 0.58473 || train_acc : 0.79988 || test_loss: 0.77933 || test_acc : 0.73690 \n",
      "Epoch: 11 || train_loss: 0.55043 || train_acc : 0.81196 || test_loss: 0.62514 || test_acc : 0.78120 \n",
      "Epoch: 12 || train_loss: 0.53563 || train_acc : 0.81382 || test_loss: 0.66237 || test_acc : 0.77580 \n",
      "Epoch: 13 || train_loss: 0.51404 || train_acc : 0.82512 || test_loss: 0.77994 || test_acc : 0.73480 \n",
      "Epoch: 14 || train_loss: 0.49355 || train_acc : 0.83026 || test_loss: 0.70469 || test_acc : 0.76070 \n",
      "Epoch: 15 || train_loss: 0.48590 || train_acc : 0.83420 || test_loss: 0.63543 || test_acc : 0.77780 \n",
      "Epoch: 16 || train_loss: 0.46914 || train_acc : 0.83978 || test_loss: 0.63307 || test_acc : 0.79290 \n",
      "Epoch: 17 || train_loss: 0.46111 || train_acc : 0.84148 || test_loss: 0.59914 || test_acc : 0.79740 \n",
      "Epoch: 18 || train_loss: 0.45022 || train_acc : 0.84442 || test_loss: 0.84449 || test_acc : 0.72940 \n",
      "Epoch: 19 || train_loss: 0.44923 || train_acc : 0.84548 || test_loss: 0.67115 || test_acc : 0.77940 \n",
      "Epoch: 20 || train_loss: 0.43373 || train_acc : 0.85168 || test_loss: 0.88164 || test_acc : 0.73030 \n",
      "Epoch: 21 || train_loss: 0.43221 || train_acc : 0.85208 || test_loss: 0.67189 || test_acc : 0.77360 \n",
      "Epoch: 22 || train_loss: 0.42555 || train_acc : 0.85380 || test_loss: 0.64112 || test_acc : 0.79310 \n",
      "Epoch: 23 || train_loss: 0.41397 || train_acc : 0.85916 || test_loss: 0.45056 || test_acc : 0.84930 \n",
      "Epoch: 24 || train_loss: 0.39764 || train_acc : 0.86548 || test_loss: 0.60443 || test_acc : 0.80480 \n",
      "Epoch: 25 || train_loss: 0.39236 || train_acc : 0.86694 || test_loss: 0.77454 || test_acc : 0.76450 \n",
      "Epoch: 26 || train_loss: 0.39401 || train_acc : 0.86700 || test_loss: 0.68934 || test_acc : 0.77970 \n",
      "Epoch: 27 || train_loss: 0.38353 || train_acc : 0.86934 || test_loss: 0.55163 || test_acc : 0.81720 \n",
      "Epoch: 28 || train_loss: 0.37490 || train_acc : 0.87322 || test_loss: 0.69036 || test_acc : 0.78700 \n",
      "Epoch: 29 || train_loss: 0.36041 || train_acc : 0.87804 || test_loss: 0.61135 || test_acc : 0.80120 \n",
      "Epoch: 30 || train_loss: 0.36158 || train_acc : 0.87626 || test_loss: 0.60164 || test_acc : 0.81070 \n",
      "Epoch: 31 || train_loss: 0.34255 || train_acc : 0.88380 || test_loss: 0.69730 || test_acc : 0.77470 \n",
      "Epoch: 32 || train_loss: 0.34007 || train_acc : 0.88636 || test_loss: 0.52781 || test_acc : 0.83250 \n",
      "Epoch: 33 || train_loss: 0.32711 || train_acc : 0.88810 || test_loss: 0.67774 || test_acc : 0.80520 \n",
      "Epoch: 34 || train_loss: 0.31604 || train_acc : 0.89200 || test_loss: 0.50914 || test_acc : 0.83160 \n",
      "Epoch: 35 || train_loss: 0.30603 || train_acc : 0.89508 || test_loss: 0.46187 || test_acc : 0.85370 \n",
      "Epoch: 36 || train_loss: 0.28688 || train_acc : 0.90184 || test_loss: 0.76645 || test_acc : 0.78110 \n",
      "Epoch: 37 || train_loss: 0.27536 || train_acc : 0.90590 || test_loss: 0.41103 || test_acc : 0.86060 \n",
      "Epoch: 38 || train_loss: 0.26378 || train_acc : 0.90896 || test_loss: 0.33736 || test_acc : 0.88680 \n",
      "Epoch: 39 || train_loss: 0.25210 || train_acc : 0.91430 || test_loss: 0.34578 || test_acc : 0.88920 \n",
      "Epoch: 40 || train_loss: 0.22044 || train_acc : 0.92504 || test_loss: 0.31910 || test_acc : 0.89470 \n",
      "Epoch: 41 || train_loss: 0.19678 || train_acc : 0.93396 || test_loss: 0.31951 || test_acc : 0.89710 \n",
      "Epoch: 42 || train_loss: 0.18033 || train_acc : 0.93778 || test_loss: 0.31067 || test_acc : 0.90010 \n",
      "Epoch: 43 || train_loss: 0.15284 || train_acc : 0.94894 || test_loss: 0.30572 || test_acc : 0.90250 \n",
      "Epoch: 44 || train_loss: 0.13012 || train_acc : 0.95592 || test_loss: 0.24748 || test_acc : 0.91850 \n",
      "Epoch: 45 || train_loss: 0.10679 || train_acc : 0.96286 || test_loss: 0.22148 || test_acc : 0.92950 \n",
      "Epoch: 46 || train_loss: 0.09019 || train_acc : 0.97010 || test_loss: 0.21415 || test_acc : 0.93110 \n",
      "Epoch: 47 || train_loss: 0.06850 || train_acc : 0.97784 || test_loss: 0.20167 || test_acc : 0.93650 \n",
      "Epoch: 48 || train_loss: 0.05713 || train_acc : 0.98148 || test_loss: 0.19644 || test_acc : 0.93770 \n",
      "Epoch: 49 || train_loss: 0.05107 || train_acc : 0.98380 || test_loss: 0.19638 || test_acc : 0.94020 \n",
      "Epoch: 50 || train_loss: 0.04923 || train_acc : 0.98446 || test_loss: 0.19485 || test_acc : 0.94020 \n"
     ]
    }
   ],
   "source": [
    "print(f\"Begin Training for {epochs} epoch\")\n",
    "test_best_acc = 1000.\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    net.train()\n",
    "    for i, (x, y) in enumerate(trainloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        pred = net(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        preds = torch.argmax(pred, dim=1)\n",
    "        train_loss += loss.item()\n",
    "        train_correct += (preds == y).sum().item()\n",
    "        train_total += y.size(0)\n",
    "        \n",
    "    test_loss = 0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    net.eval()\n",
    "    for x, y in testloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = net(x)\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            preds = torch.argmax(pred, dim=1)\n",
    "            test_loss += loss.item()\n",
    "            test_correct += (preds == y).sum().item()\n",
    "            test_total += y.size(0)\n",
    "\n",
    "    print(f'Epoch: {epoch} || train_loss: {train_loss / ((num_train - 1) // bs_train + 1):.5f} || train_acc : {train_correct / train_total:.5f} || test_loss: {test_loss / ((num_test - 1) // bs_test + 1):.5f} || test_acc : {test_correct / test_total:.5f} ')\n",
    "    \n",
    "    if test_best_acc > test_correct / test_total:\n",
    "        torch.save(net.state_dict(), 'models/CIFAR10/ResNet18/model.pt')\n",
    "        \n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': train_loss / ((num_train - 1) // bs_train + 1),\n",
    "            }, \"models/CIFAR10/ResNet18/last_checkpoints.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
